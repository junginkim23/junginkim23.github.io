---
title : "[Data Science] Data Process & EDA"
excerpt: "데이터 분석의 가장 기본인 전처리와 EDA에 대해 알아보자."
header:
    teaser: /assets/datascience.png
category :
    - Data Science 
tag : 
    - EDA
    - Data-Processing
toc : true 
toc_sticky: true
---

<img src='/assets/datascience.png' width = 1000 height = 500 >

#### 개요

이번 시간에는 EDA가 무엇이고 데이터 전처리 과정이 어떻게 되는지에 대해서 알아볼 것이다.

#### 1. 데이터 셋 불러오기 

##### 1-1. read_csv()

```py
import pandas as pd

ktng_data_url = 'https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/kt%26g/kt%26g_0.csv'
df = pd.read_csv(ktng_data_url)
df.head()
```
<img src='/assets/dff.PNG' width = 1000 height = 10>

>names = ['column명1','column명2','column명3','column명4',...]  옵션 사용

해당 옵션 사용 시 데이터프레임의 컬럼 이름 지정.

```py
column_headers = ['분기','매출액','영업이익'
                  ,'영업이익(발표기준)','세전계속사업이익',
                  '당기순이익','당기순이익(지배)'
                  ,'당기순이익(비지배)','자산총계','부채총계',
                  '자본총계','자본총계(지배)','자본총계(비지배)'
                  ,'자본금','영업활동현금흐름',
                  '투자활동현금흐름','재무활동현금흐름',
                  '영업이익률','순이익률','ROE(%)',
                  'ROA(%)','부채비율','자본유보율','EPS(원)','PER(배)']
df = pd.read_csv(ktng_data_url,names = column_headers)

df.head()
```
<img src='/assets/dfff.PNG' width = 1000 height = 100>

>print(df.head())와 df.head()의 차이는 무엇일까?

```py
print(type(df.head())) #output: <class 'pandas.core.frame.DataFrame'>
type(df.head()) #output: pandas.core.frame.DataFrame
```

##### 1-2. file.upload()

해당 코드를 사용하면 구글 코랩 파일 목록에 새로운 파일을 추가할 수 있다.

```py
from google.colab import files 

uploaded = files.upload()
```

#### 2. EDA(Exploratory Data Analysis)

##### 2-1. EDA란?

>EDA란, 데이터 분석에 있어서 매우 중요한, 초기 분석의 단계를 의미합니다. 전처리 과정전에 데이터가 의미하는 바가 무엇이고 데이터 안에 결측치가 있는지 쓸데없는 데이터가 무엇인지 등을 파악하는 과정이라고도 볼 수 있다.

- 시각화 같은 도구를 통해서 패턴을 발견하거나
- 데이터의 특이성을 확인하거나
- 통계와 그래픽을 통해서 가설을 검정하는 과정 등을 포함합니다.


##### 2-2. EDA의 방법(Graphic, Non-Graphic) 

>**1. Graphic**
: 차트 혹은 그림 등을 이용하여 데이터를 확인하는 방법이다. 

>**2. Non-Graphic** 
: 그래픽적인 요소를 사용하지 않는 방법으로, 주로 Summary Statistics를 통해 데이터를 확인하는 방법이다.

##### 2-3. EDA 타겟 데이터(Univariate, Multi-variate)

>**1. Univariate**
: 타겟 데이터가 변수 하나 

>**2. Multi-variate**
: 여러 변수들간의 관계를 본다. 

##### 2-4. Uni - Non Graphic & Uni - Graphic 

>**1. Uni - Non Graphic**
: 각 변수마다 통계요약치를 사용해서 각 데이터를 분석한다.

Numeric data의 경우 summary statistics를 제일 많이 사용한다. 이에는

- Center (Mean, Median, Mod)
- Spread (Variance, SD, IQR, Range)
- Modality (Peak)
- Shape (Tail, Skewness, Kurtosis)
- Outliers(이상치) 

등을 확인한다. 

Categorical data의 경우 occurence, frequency, tabulation(도표 작성, 표)을 많이 사용한다.

>**2. Uni - Graphic**
: Histogram, Pie Chart(원 그래프), Stem-leaf plot(줄기 잎 그림), Boxplot, QQPlot 등을 사용한다. 

**boxplot?**

박스플랏은 데이터가 많아 눈으로 확인하기 어려울 때 그림을 이용해 데이터 집합의 범위와 중앙값을 빠르게 확인할 수 있는 목적으로 사용한다. 

**QQPlot?**

qqplot은 분위수대조도로 불리며 정규모집단 가정을 하는 방법 중 하나이며 수집 데이터를 표준 정규분포의 분위수와 비교하여 그리는 그래프.

_분위수_ 란, 데이터의 분포에서 전체 넓이를 일정 비로 나누어 위치에 있는 값을 말한다.

##### 2-5. Multi - Non Graphic & Multi - Graphic

>**1. Multi - Non Graphic**
: 여러 변수들 간의 관계를 보는 것이 주 목적이다. 
- Cross - Tabulation(도표)
- Cross-Statistics(Correlation, Covariance)

Categorical data는 cross tabulation을 적용할 수 있으며 Numerical data는 Cross Statistics을 통해 데이터 분석을 할 수 있습니다.

>**2. Multi - Graphic**
여러 변수들간의 관계를 그래프로 표현

- Category & Numeric 
    - boxplots
    - stacked bar
    - parallel coordinate
    - heatmap

- Numeric & Numeric
    - scatter plot 


#### 3. Data Preprocessing process

##### 3-1. Data Cleaning 

데이터를 분석하기 전에 **오류**를 수정하고 결측값을 제거하는 등의 작업을 하지 않으면 우리가 원하는 인사이트를 도출하는데 어려움을 겪을 수 있다. 

이러한 문제를 겪지 않기 위해 데이터의 정확성, 완성도, 일관성, 신뢰성을 유지하기 위해 불필요한 데이터를 삭제하는 과정이다.

##### 3-2. Data Integration

cleaning 작업을 끝낸 데이터들이 여러 개가 존재하고 해당 데이터들 중 몇 개의 데이터들을 분석하기 편하게 하나로 합치는 과정이라고 보면 된다. 예시로 **concat**이나 **merge**가 있다.

##### 3-3. Data Transformation

데이터의 형태를 변환하는 작업이다. 정규화 혹은 표준화도 이것의 일종이며 **Scaling**이라고도 부른다. 쉽게 생각하면 **정수의 데이터를 실수의 데이터로 변환**하는 것도 데이터 변환의 일종이다.

##### 3-4. Data Reduction

데이터를 의미있게 줄이는 과정이라고 보면 되는데, dimension reduction과 유사한 목적을 갖는다. 데이터 차원의 축소뿐만 아니라 데이터의 행과 열을 삭제해서 줄이는 것도 포함된다.